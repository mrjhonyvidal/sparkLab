# -*- coding: utf-8 -*-
"""PairRDDs - Key and Value.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QhCaNX7QGASVWYVxkoInbU6_L7kds5be
"""

!pip install pyspark

from pyspark import SparkContext

"""# Creating a Pair RDD from a list of Tuple"""

sc = SparkContext()

list_tuples = [('a', 1), ('b', 2), ('c', 3)]

list_tuples

pair_rdd = sc.parallelize(list_tuples)

pair_rdd.collect()

## Utilizing zip()

pair_rdd2 = sc.parallelize(zip((['a','b','c']),range(1,4,1))) #start, stop, range

?range # Show help adding ? before command

pair_rdd2.collect()

## zip with two RDDs

rdd1 = sc.parallelize(range(5),3)

rdd2 = sc.parallelize(range(100, 105, 1), 3) ## Both RDD must have the same number of partitions, in this case 3

rdd1.glom().collect() ## Check partitions

rdd2.glom().collect()

pair_rdd =  rdd1.zip(rdd2)

pair_rdd.collect()

pair_rdd.glom().collect()

### Creating from a file, note: as we're using Codelab Runtime, files uploaded are not persisted after reload. Please head to: https://github.com/mrjhonyvidal/sparkLab/tree/master/pyspark/count_number_words_in_text to get the file La+Celestina.txt

rdd_celestina = sc.textFile("La+Celestina.txt")

pair_rdd_celestina = rdd_celestina.map(lambda x: (x.split(" ")[0],x))

pair_rdd_celestina.takeSample(False, 15)

## Using KeyBy

rdd = sc.parallelize(range(5))

rdd.collect()

pair_rdd = rdd.keyBy(lambda x: x + 1)

pair_rdd.collect()

## ZipWithIndex

## ZipWithUniqueId()

